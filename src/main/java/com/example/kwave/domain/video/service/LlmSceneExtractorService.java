package com.example.kwave.domain.video.service;

import com.example.kwave.global.config.OpenAiConfig;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.http.*;
import org.springframework.stereotype.Service;
import org.springframework.web.client.RestTemplate;

import java.util.List;
import java.util.Map;

@Slf4j
@Service
@RequiredArgsConstructor
public class LlmSceneExtractorService {

    private final OpenAiConfig openAiConfig;

    private static final String OPENAI_API_URL = "https://api.openai.com/v1/chat/completions";

    /**
     * ë‰´ìŠ¤ ë³¸ë¬¸ì„ ì…ë ¥ë°›ì•„ ì¥ë©´(Scene) JSON ë¦¬ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œ
     * - SceneDto êµ¬ì¡°ì™€ ì¼ì¹˜í•˜ëŠ” JSON ë°°ì—´ì„ ë°˜í™˜
     * - ê° ì¥ë©´ì€ { "sceneIndex": int, "description": string, "extraPrompt": string }
     */
    public String extractScenes(String newsText) {
        RestTemplate restTemplate = new RestTemplate();
        /*
        // âœ… ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (LLMì˜ ì—­í•  ì •ì˜)
        String systemPrompt = """
            ë„ˆëŠ” ì˜ìƒ ì—°ì¶œ ë³´ì¡° AIì•¼.
            ì•„ë˜ ë‰´ìŠ¤ ë³¸ë¬¸ì„ ë³´ê³  ì‹œê°ì ìœ¼ë¡œ í‘œí˜„í•˜ê¸° ì¢‹ì€ ì¥ë©´ 4~5ê°œë¥¼ ë½‘ì•„.
            ê° ì¥ë©´ì€ JSON ë°°ì—´ë¡œ í‘œí˜„í•˜ê³ , ê° ì›ì†ŒëŠ” ë‹¤ìŒ í˜•ì‹ì„ ë”°ë¼:
            
            [
              {
                "sceneIndex": 1,
                "description": "ë¬´ëŒ€ ìœ„ì—ì„œ ê°€ìˆ˜ë¥¼ ë¹„ì¶”ëŠ” ì¥ë©´",
                "extraPrompt": "A dynamic concert stage with bright lights, cinematic style"
              },
              ...
            ]
            
            ë°˜ë“œì‹œ JSON ë°°ì—´ë§Œ ì¶œë ¥í•˜ê³ , ì„¤ëª… ë¬¸ì¥ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆ.
        """;
        */

        String systemPrompt = """
                You are an AI Video Director Assistant.
                
                Your task is to analyze the provided news text and extract exactly 5 scenes that are most suitable for short-form visual representation.
                
                Each scene prompt must be designed as:
                - a 5-second clip,
                - framed specifically for a 9:16 vertical (shorts) video format.
                
                Output the result strictly as a JSON array. Each object in the array must follow this format:
                
                [
                  {
                    "sceneIndex": 1,
                    "description": "Describe the specific scene here in Korean.",
                    "extraPrompt": "Describe the visual prompts here in English (must explicitly mention 9:16 vertical framing and short 5-second composition)."
                  },
                  ...
                ]
                
                Constraints:
                1. The value of `description` must be written in Korean.
                2. The value of `extraPrompt` must be written in English and must clearly instruct a 5-second, 9:16 vertical video composition.
                
                3. EXTREME RESTRICTIONS ON PEOPLE:
                   - Do NOT describe any specific individual.
                   - Do NOT describe identifiable people (e.g., singer, performer, dancer, politician, reporter).
                   - Do NOT mention any human actions, poses, gestures, or facial expressions.
                   - Only anonymous, distant groups such as 'êµ°ì¤‘', 'ì‚¬ëŒë“¤', 'ê´€ê°' may appear, and ONLY as background silhouettes.
                   - No recognizable humans, no single-person focus.
                
                4. STRICT BAN ON PROPER NOUNS:
                   - No real names, celebrity names, organization names, or location names.
                   - Use only generic scene descriptions (e.g., "ë„ì‹œ ê±°ë¦¬", "ë¬´ëŒ€", "ê°€ìƒ ê³µê°„").
                
                5. SCENE FOCUS RULE:
                   - Scenes must focus on environments, landscapes, objects, atmospheres, or symbolic visuals.
                   - Not people.
                
                6. FORMAT REQUIREMENTS:
                   - Each scene must be visually strong, simple, and optimized for a short 5-second 9:16 vertical video shot.
                   - No markdown, no explanations. Output ONLY the JSON array.
                
                Generate exactly 5 scenes.
        """;

        // âœ… ìš”ì²­ ë³¸ë¬¸ êµ¬ì„±
        Map<String, Object> body = Map.of(
                "model", openAiConfig.getChatModel(),
                "messages", List.of(
                        Map.of("role", "system", "content", systemPrompt),
                        Map.of("role", "user", "content", newsText)
                ),
                "temperature", 0.7
        );

        HttpHeaders headers = new HttpHeaders();
        headers.setContentType(MediaType.APPLICATION_JSON);
        headers.setBearerAuth(openAiConfig.getApiKey());

        try {
            ResponseEntity<Map> response = restTemplate.exchange(
                    OPENAI_API_URL,
                    HttpMethod.POST,
                    new HttpEntity<>(body, headers),
                    Map.class
            );

            Map<String, Object> result = response.getBody();
            if (result == null || result.get("choices") == null) {
                throw new RuntimeException("LLM ì‘ë‹µì´ ë¹„ì •ìƒì…ë‹ˆë‹¤.");
            }

            // âœ… LLM ê²°ê³¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            String content = ((Map<String, String>)
                    ((Map<String, Object>) ((List<?>) result.get("choices")).get(0))
                            .get("message")).get("content");

            if (content == null || content.isBlank()) {
                throw new RuntimeException("LLMì´ ë¹ˆ ì‘ë‹µì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.");
            }

            log.info("ğŸ¬ LLM Scene JSON ê²°ê³¼:\n{}", content.trim());
            return content.trim(); // âœ… JSON ë¬¸ìì—´ ê·¸ëŒ€ë¡œ ë°˜í™˜

        } catch (Exception e) {
            log.error("âŒ LLM Scene ì¶”ì¶œ ì‹¤íŒ¨: {}", e.getMessage(), e);
            throw new RuntimeException("LLM Scene ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ", e);
        }
    }
}